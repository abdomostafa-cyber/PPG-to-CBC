{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d971c3",
   "metadata": {},
   "source": [
    "# ðŸ§ª labs_data_cleaning_param.ipynb\n",
    "\n",
    "Streaming-friendly lab data cleaner for large MIMIC-III LABEVENTS files.\n",
    "\n",
    "This notebook:\n",
    "- Reads LABEVENTS.csv in chunks (memory-safe)\n",
    "- Filters for CBC tests\n",
    "- Keeps only rows where FLAG == 'abnormal' or NaN (normal)\n",
    "- Encodes FLAG as 1 (abnormal) or 0 (normal)\n",
    "- Formats SUBJECT_ID as 'pXXXXXX'\n",
    "- Uses configs/labs_cleaning.yaml for settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, importlib\n",
    "print('Python:', sys.version.split()[0])\n",
    "for pkg in ['pandas','numpy','yaml']:\n",
    "    try:\n",
    "        m = importlib.import_module(pkg)\n",
    "        print(pkg, getattr(m, '__version__', 'n/a'))\n",
    "    except Exception as e:\n",
    "        print(pkg, 'not installed:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a7fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load configuration\n",
    "from pathlib import Path\n",
    "import yaml, os\n",
    "\n",
    "CFG_PATH = os.environ.get(\"CFG\", \"configs/labs_cleaning.yaml\")\n",
    "with open(CFG_PATH, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "L = cfg[\"labs_cleaning\"]\n",
    "print(\"Loaded configuration from:\", CFG_PATH)\n",
    "print(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b856b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Streaming cleaner (avoids OOM, processes 18GB+ files safely)\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from csv import QUOTE_MINIMAL\n",
    "\n",
    "def choose_col(df, candidates, required=False, name=\"\"):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Required column not found for {name}: candidates={candidates}\")\n",
    "    return None\n",
    "\n",
    "def load_d_labitems(path):\n",
    "        if path and Path(path).exists():\n",
    "            d = pd.read_csv(path, low_memory=False)\n",
    "            label_col = next((c for c in [\"LABEL\",\"label\",\"TESTNAME\",\"test_name\"] if c in d.columns), None)\n",
    "            itemid_col = next((c for c in [\"ITEMID\",\"itemid\"] if c in d.columns), None)\n",
    "            fluid_col = next((c for c in [\"FLUID\",\"fluid\",\"SPECIMEN\",\"specimen\",\"SPECIMEN_TYPE\",\"specimen_type\"] if c in d.columns), None)\n",
    "            keep_cols = {}\n",
    "            if itemid_col: keep_cols[itemid_col] = \"ITEMID\"\n",
    "            if label_col: keep_cols[label_col] = \"LABEL\"\n",
    "            if fluid_col: keep_cols[fluid_col] = \"FLUID\"\n",
    "            if keep_cols:\n",
    "                return d[list(keep_cols.keys())].rename(columns=keep_cols)\n",
    "        return None\n",
    "\n",
    "def normalize_cbc_label(s: pd.Series) -> pd.Series:\n",
    "        if s is None: return None\n",
    "        s2 = s.astype(\"string\").str.strip().str.lower()\n",
    "        # map common RBC/WBC variants to canonical tokens\n",
    "        mapping = {\n",
    "            \"rbc\": \"RBC\",\n",
    "            \"rbc count\": \"RBC\",\n",
    "            \"red blood cells\": \"RBC\",\n",
    "            \"red blood cell count\": \"RBC\",\n",
    "            \"wbc\": \"WBC\",\n",
    "            \"wbc count\": \"WBC\",\n",
    "            \"white blood cells\": \"WBC\",\n",
    "            \"white blood cell count\": \"WBC\",\n",
    "        }\n",
    "        # Also collapse extra spaces\n",
    "        s2 = s2.str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        return s2.map(mapping).fillna(s)  # return canonical if matched else original\n",
    "\n",
    "def normalize_flags(s):\n",
    "    if s is None: return None\n",
    "    s2 = s.astype(str).str.lower().str.strip()\n",
    "    return s2.replace({\n",
    "        \"abnormal\": \"abnormal\",\n",
    "        \"high\": \"high\",\n",
    "        \"low\": \"low\",\n",
    "        \"pos\": \"positive\",\n",
    "        \"neg\": \"negative\",\n",
    "        \"positive\": \"positive\",\n",
    "        \"negative\": \"negative\"\n",
    "    })\n",
    "\n",
    "Path(Path(L[\"output_clean_csv\"]).parent).mkdir(parents=True, exist_ok=True)\n",
    "# Remove previous output to avoid mixing with older runs\n",
    "out_csv_path = Path(L[\"output_clean_csv\"])\n",
    "if out_csv_path.exists():\n",
    "    out_csv_path.unlink()\n",
    "\n",
    "dli = load_d_labitems(L.get(\"d_labitems_csv\"))\n",
    "cbc_labels = set(L.get(\"cbc_labels\", []))\n",
    "cbc_itemids = set(L.get(\"cbc_itemids\", []))\n",
    "canonical_cbc_labels = set(L.get(\"cbc_labels\", [])) | {\"RBC\",\"WBC\"}\n",
    "if not cbc_itemids and dli is not None and cbc_labels:\n",
    "    cbc_itemids = set(dli.loc[dli[\"LABEL\"].isin(cbc_labels), \"ITEMID\"].astype(\"Int64\").dropna().astype(int).tolist())\n",
    "\n",
    "sample = pd.read_csv(L[\"labs_csv\"], nrows=1000, low_memory=False)\n",
    "col_subject = choose_col(sample, L[\"columns\"][\"subject_id\"]) or \"SUBJECT_ID\"\n",
    "col_time    = choose_col(sample, L[\"columns\"][\"charttime\"]) or \"CHARTTIME\"\n",
    "col_itemid  = choose_col(sample, L[\"columns\"][\"itemid\"]) or \"ITEMID\"\n",
    "col_label   = choose_col(sample, L[\"columns\"][\"label\"])\n",
    "col_value   = choose_col(sample, L[\"columns\"][\"value\"]) or \"VALUENUM\"\n",
    "col_uom     = choose_col(sample, L[\"columns\"][\"valueuom\"]) or \"VALUEUOM\"\n",
    "col_flag    = choose_col(sample, L[\"columns\"][\"flag\"])\n",
    "fluid_candidates = [c for c in [\"FLUID\",\"fluid\",\"SPECIMEN\",\"specimen\",\"SPECIMEN_TYPE\",\"specimen_type\"] if c in sample.columns]\n",
    "col_fluid = fluid_candidates[0] if fluid_candidates else None\n",
    "\n",
    "usecols = sorted(set(filter(None, [col_subject, col_time, col_itemid, col_label, col_value, col_uom, col_flag])))\n",
    "dtype_map = {}\n",
    "if col_itemid: dtype_map[col_itemid] = \"Int64\"\n",
    "if col_value: dtype_map[col_value] = \"float32\"\n",
    "if col_subject: dtype_map[col_subject] = \"Int64\"\n",
    "\n",
    "wrote_header = False\n",
    "kept = 0\n",
    "total = 0\n",
    "chunksize = int(L.get(\"chunksize\", 300_000))\n",
    "\n",
    "for chunk in pd.read_csv(L[\"labs_csv\"], usecols=usecols, dtype=dtype_map, chunksize=chunksize, low_memory=True):\n",
    "        # Normalize label variants for RBC/WBC\n",
    "        norm_label = normalize_cbc_label(chunk[col_label]) if col_label else None\n",
    "        # If D_LABITEMS has FLUID, join it for fluid filtering\n",
    "        fluid_series = None\n",
    "        if dli is not None and \"ITEMID\" in dli.columns and col_itemid:\n",
    "            fluid_series = chunk[[col_itemid]].merge(dli[[\"ITEMID\",\"FLUID\"]], left_on=col_itemid, right_on=\"ITEMID\", how=\"left\")[\"FLUID\"]\n",
    "        elif col_fluid:\n",
    "            fluid_series = chunk[col_fluid]\n",
    "    total += len(chunk)\n",
    "    mask = pd.Series(False, index=chunk.index)\n",
    "    if cbc_itemids:\n",
    "        mask = mask | chunk[col_itemid].isin(list(cbc_itemids))\n",
    "    if col_label and cbc_labels:\n",
    "        mask = mask | chunk[col_label].astype(str).isin(cbc_labels)\n",
    "    chunk = chunk[mask]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # Standardize raw flag: lower/strip; treat '', 'nan', 'none', 'normal' as NaN\n",
    "        raw_flag = (chunk[col_flag] if col_flag else None)\n",
    "        if raw_flag is not None:\n",
    "            std_flag = raw_flag.astype(\"string\").str.strip().str.lower().replace({\"\": pd.NA, \"nan\": pd.NA, \"none\": pd.NA, \"normal\": pd.NA})\n",
    "        else:\n",
    "            std_flag = None\n",
    "\n",
    "        out = pd.DataFrame({\n",
    "            \"subject_id\": chunk[col_subject].astype(\"Int64\"),\n",
    "            \"charttime\": pd.to_datetime(chunk[col_time], errors=\"coerce\"),\n",
    "            \"label\": (norm_label.where(norm_label.isin([\"RBC\",\"WBC\"])) if norm_label is not None else (chunk[col_label].astype(str) if col_label else None)),\n",
    "            \"itemid\": chunk[col_itemid].astype(\"Int64\") if col_itemid else None,\n",
    "            \"value\": pd.to_numeric(chunk[col_value], errors=\"coerce\") if col_value else None,\n",
    "            \"valueuom\": chunk[col_uom].astype(str) if col_uom else None,\n",
    "            \"flag\": std_flag,\n",
    "        })\n",
    "\n",
    "    # Keep only abnormal or NaN flags, encode abnormal->1, NaN->0\n",
    "        if \"flag\" in out.columns:\n",
    "            out = out[(out[\"flag\"] == \"abnormal\") | (out[\"flag\"].isna())]\n",
    "            out[\"flag\"] = out[\"flag\"].map({\"abnormal\": 1}).fillna(0).astype(\"Int8\")\n",
    "\n",
    "    # Format subject_id as pXXXXXX\n",
    "    out[\"subject_id\"] = out[\"subject_id\"].apply(lambda x: f\"p{int(x):06d}\" if pd.notna(x) else x)\n",
    "\n",
    "    # Drop missing value rows if configured\n",
    "    if L.get(\"drop_na_value\", True):\n",
    "        out = out[out[\"value\"].notna()]\n",
    "\n",
    "    out[\"charttime\"] = out[\"charttime\"].dt.strftime(L.get(\"time_format_out\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "    kept += len(out)\n",
    "    out.to_csv(L[\"output_clean_csv\"], mode=\"a\", index=False, header=(not wrote_header), quoting=QUOTE_MINIMAL)\n",
    "    wrote_header = True\n",
    "\n",
    "print(f\"âœ… Streaming complete. Scanned ~{total:,} rows; kept ~{kept:,}.\")\n",
    "print(f\"Output saved to: {L['output_clean_csv']}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
