{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912b1765",
   "metadata": {},
   "source": [
    "# mat_modifier (parameterized)\n",
    "\n",
    "This version removes hardcoded paths and reads everything from `configs/default.yaml`.\n",
    "It produces per-subject reduced `.mat` files containing PPG, ABP, and a small metadata block,\n",
    "and writes a `manifest.json` with a summary of what was created.\n",
    "\n",
    "**Run order:** Run all cells top-to-bottom. Make sure `configs/default.yaml` exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "172278c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.11.9\n",
      "yaml: 6.0.1\n",
      "scipy: 1.13.1\n",
      "numpy: 2.0.2\n",
      "mat73: n/a\n"
     ]
    }
   ],
   "source": [
    "# Environment report (optional but helps reproducibility)\n",
    "import sys, importlib\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "for pkg in [\"yaml\", \"scipy\", \"numpy\", \"mat73\"]:\n",
    "    try:\n",
    "        m = importlib.import_module(pkg)\n",
    "        v = getattr(m, \"__version__\", \"n/a\")\n",
    "        print(f\"{pkg}:\", v)\n",
    "    except Exception as e:\n",
    "        print(f\"{pkg}: not installed ({e})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd8315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from: configs/default.yaml\n",
      "RAW_DIR: data\\mimic_waveforms\n",
      "OUT_DIR: data\\reduced_waveforms\n",
      "GLOB_PAT: *.mat\n",
      "GROUP_NAME: Subj_Wins\n",
      "KEYS_TO_INCLUDE: ['Age', 'CaseID', 'Gender', 'PPG_Raw', 'SegmentID', 'SubjectID', 'T']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Config & imports ---\n",
    "from pathlib import Path\n",
    "import yaml, json\n",
    "# Prefer mat73 for MATLAB v7.3 files; fallback to scipy for older versions\n",
    "try:\n",
    "    import mat73\n",
    "    def load_mat(path): return mat73.loadmat(str(path))\n",
    "except Exception as e:\n",
    "    from scipy.io import loadmat as scipy_loadmat\n",
    "    def load_mat(path): return scipy_loadmat(path, simplify_cells=True)\n",
    "\n",
    "# You can override this via environment variable in notebooks if needed:\n",
    "# %env CFG=configs/alt.yaml\n",
    "import os\n",
    "CFG_PATH = os.environ.get(\"CFG\", \"configs/default.yaml\")\n",
    "\n",
    "with open(CFG_PATH, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "RAW_DIR   = Path(cfg[\"paths\"][\"raw_waveforms\"])\n",
    "OUT_DIR   = Path(cfg[\"paths\"][\"reduced_waveforms\"])\n",
    "GLOB_PAT  = cfg[\"mat_modifier\"][\"glob\"]\n",
    "\n",
    "GROUP_NAME = cfg[\"mat_modifier\"].get(\"group_name\", \"Subj_Wins\")\n",
    "KEYS_TO_INCLUDE = cfg[\"mat_modifier\"][\"keys_to_include\"]\n",
    "TF = cfg[\"mat_modifier\"].get(\"time_fields\", {})\n",
    "print(\"Config loaded from:\", CFG_PATH)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "print(\"GLOB_PAT:\", GLOB_PAT)\n",
    "print(\"GROUP_NAME:\", GROUP_NAME)\n",
    "print(\"KEYS_TO_INCLUDE:\", KEYS_TO_INCLUDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b62100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core logic copied from user's working approach (parameterized) ---\n",
    "import numpy as np, pandas as pd, os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "def process_data(data, output_group, keys_to_include):\n",
    "    for key, value in data.items():\n",
    "        if key not in keys_to_include:\n",
    "            continue\n",
    "        if isinstance(value, dict):\n",
    "            sub_group = output_group.create_group(key)\n",
    "            process_data(value, sub_group, keys_to_include)\n",
    "        else:\n",
    "            try:\n",
    "                if isinstance(value, list):\n",
    "                    value = np.array(value)\n",
    "                if isinstance(value, np.ndarray) and value.dtype == 'object':\n",
    "                    uniform_array = np.array([np.asarray(x) for x in value])\n",
    "                    output_group.create_dataset(key, data=uniform_array)\n",
    "                elif isinstance(value, np.ndarray) and value.size == 1:\n",
    "                    scalar_value = value.item()\n",
    "                    output_group.create_dataset(key, data=scalar_value)\n",
    "                elif isinstance(value, np.ndarray) and np.issubdtype(value.dtype, np.str_):\n",
    "                    output_group.create_dataset(key, data=value.astype('S'))\n",
    "                else:\n",
    "                    output_group.create_dataset(key, data=value)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing key {key}: {e}\")\n",
    "\n",
    "def process_mat_file(input_file: str, output_file: str):\n",
    "    group_name = cfg[\"mat_modifier\"].get(\"group_name\", \"Subj_Wins\")\n",
    "    keys_to_include = cfg[\"mat_modifier\"][\"keys_to_include\"]\n",
    "    case_fmt = cfg[\"mat_modifier\"].get(\"time_fields\", {}).get(\"case_id_format\", \"%Y-%m-%d-%H-%M\")\n",
    "    seconds_per_segment = int(cfg[\"mat_modifier\"].get(\"time_fields\", {}).get(\"seconds_per_segment\", 10))\n",
    "    output_time_key = cfg[\"mat_modifier\"].get(\"time_fields\", {}).get(\"output_key\", \"Segment_Time\")\n",
    "    output_time_fmt = cfg[\"mat_modifier\"].get(\"time_fields\", {}).get(\"output_format\", \"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "    # Load the .mat file\n",
    "    mat_data = load_mat(input_file)\n",
    "\n",
    "    subj = mat_data.get(group_name)\n",
    "    if subj is None:\n",
    "        for k, v in mat_data.items():\n",
    "            if isinstance(k, str) and k.lower() == group_name.lower():\n",
    "                subj = v; break\n",
    "    assert isinstance(subj, dict), f\"{group_name} not found or not a dict\"\n",
    "\n",
    "    case_ids_list = subj.get('CaseID')\n",
    "    segment_ids_list = subj.get('SegmentID')\n",
    "\n",
    "    if type(case_ids_list) == list and type(segment_ids_list) == list:\n",
    "        case_ids = [case_id[0] for case_id in case_ids_list]\n",
    "        segment_ids = [segment_id[0] for segment_id in segment_ids_list]\n",
    "        df = pd.DataFrame({'CaseID': case_ids, 'SegmentID': segment_ids})\n",
    "        df['CaseID_datetime'] = pd.to_datetime(df['CaseID'], format=case_fmt)\n",
    "        df['SegmentTime'] = df['SegmentID'] * seconds_per_segment\n",
    "        df['FinalTime'] = df['CaseID_datetime'] + pd.to_timedelta(df['SegmentTime'], unit='s')\n",
    "        df['FinalTime_str'] = df['FinalTime'].dt.strftime(output_time_fmt)\n",
    "        Segment_Time = df['FinalTime_str'].values.reshape(-1, 1)\n",
    "        subj[output_time_key] = Segment_Time\n",
    "\n",
    "    with h5py.File(output_file, 'w') as out_f:\n",
    "        g = out_f.create_group(group_name)\n",
    "        process_data(subj, g, keys_to_include)\n",
    "        if output_time_key in subj:\n",
    "            g.create_dataset(output_time_key, data=subj[output_time_key].astype('S'))\n",
    "\n",
    "def reduce_mat_file(in_path: Path):\n",
    "    out_path = OUT_DIR / in_path.name\n",
    "    process_mat_file(str(in_path), str(out_path))\n",
    "    present = {\n",
    "        \"PPG\": \"PPG_Raw\" in load_mat(in_path).get(cfg[\"mat_modifier\"][\"group_name\"], {}),\n",
    "    }\n",
    "    sid = Path(in_path).stem\n",
    "    return {\"input\": str(in_path), \"output\": str(out_path), \"subject_id\": sid, \"present\": present}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe898211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] p000160.mat → data\\reduced_waveforms\\p000160.mat\n",
      "Done. Wrote 1 reduced files and manifest → data\\reduced_waveforms\\manifest.json\n"
     ]
    }
   ],
   "source": [
    "# --- Run over all input files and write manifest.json ---\n",
    "files = sorted(RAW_DIR.glob(GLOB_PAT))\n",
    "assert files, f\"No files matched '{GLOB_PAT}' in {RAW_DIR}\"\n",
    "\n",
    "manifest = []\n",
    "for i, f in enumerate(files, 1):\n",
    "    try:\n",
    "        entry = reduce_mat_file(f)\n",
    "        manifest.append(entry)\n",
    "        if i % 50 == 0 or i == len(files):\n",
    "            print(f\"[{i}/{len(files)}] {f.name} → {entry['output']}\")\n",
    "    except Exception as e:\n",
    "        print(\"ERROR:\", f, e)\n",
    "\n",
    "manifest_path = OUT_DIR / \"manifest.json\"\n",
    "manifest_path.write_text(json.dumps(manifest, indent=2))\n",
    "print(f\"Done. Wrote {len(manifest)} reduced files and manifest → {manifest_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "578160e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ABP_Raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/Repo files/data/reduced_waveforms/p000160.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     25\u001b[0m data \u001b[38;5;241m=\u001b[39m load_h5_file(input_file)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubj_Wins\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mABP_Raw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ABP_Raw'"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat as scipy_loadmat\n",
    "from mat73 import loadmat\n",
    "\n",
    "def load_h5_file(file_path):\n",
    "    def recursively_load_data(h5_obj):\n",
    "        if isinstance(h5_obj, h5py.Dataset):\n",
    "            data = h5_obj[()]\n",
    "            if isinstance(data, bytes):  # Decode byte strings\n",
    "                return data.decode()\n",
    "            elif isinstance(data, np.ndarray) and data.dtype.type is np.bytes_:\n",
    "                return data.astype(str)  # Decode byte strings in numpy arrays\n",
    "            return data\n",
    "        elif isinstance(h5_obj, h5py.Group):\n",
    "            data = {}\n",
    "            for key, item in h5_obj.items():\n",
    "                data[key] = recursively_load_data(item)\n",
    "            return data\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type: {type(h5_obj)}\")\n",
    "\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        return recursively_load_data(f)\n",
    "\n",
    "input_file = 'D:/Repo files/data/reduced_waveforms/p000160.mat'\n",
    "data = load_h5_file(input_file)\n",
    "data['Subj_Wins']['ABP_Raw'][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simedy2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
