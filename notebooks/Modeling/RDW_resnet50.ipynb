{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "# from scipy.signal import spectrogram\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "from tqdm.notebook import tqdm\n",
    "# import io\n",
    "# import zipfile\n",
    "# from google.oauth2 import service_account\n",
    "# from googleapiclient.discovery import build\n",
    "# from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "#Import my functions\n",
    "import nbimporter\n",
    "from Functions import MyDataset, download_dataset, train, validate, plot_loss_accuracy\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {str(i): 'float64' for i in range(5000)}\n",
    "dtypes.update({\n",
    "    'Segment_Time': 'str',\n",
    "    'lab_flag': 'int',\n",
    "    'Gender': 'str',\n",
    "    'Age': 'float64',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_location = 'D:/simedy' # Change this to the location of the repository on your machine\n",
    "\n",
    "test = 'RDW'\n",
    "panel = 'CBC'\n",
    "time = '15 min'\n",
    "gender_age_used = \"No_GA\"\n",
    "file_path = os.path.join(repo_location, f'CSVs/Alldata_{test}_{time}.csv')\n",
    "\n",
    "#if path does not exist, download the dataset\n",
    "if not os.path.exists(file_path):\n",
    "    download_dataset(repo_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, dtype=dtypes)\n",
    "if gender_age_used == \"No_GA\":\n",
    "    df = df.drop(columns=['Gender', 'Age'])\n",
    "if 'SubjectID' in df.columns:\n",
    "    df = df.drop(columns=['SubjectID'])\n",
    "df.lab_flag.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: lab_flag\n",
      "1    83305\n",
      "0    16661\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Downsample the class with the majority of data\n",
    "df_majority = df[df.lab_flag == df.lab_flag.value_counts().index[0]]  \n",
    "df_minority = df[df.lab_flag == df.lab_flag.value_counts().index[1]]\n",
    "\n",
    "# If the majority class is at least 5 times the size of the minority class\n",
    "if len(df_majority) / len(df_minority) >= 5:\n",
    "    # Downsample majority class\n",
    "    df_majority_downsampled = df_majority.sample(n=int(len(df_minority)*5), random_state=42)\n",
    "\n",
    "    # Combine minority class with downsampled majority class\n",
    "    df = pd.concat([df_majority_downsampled, df_minority])\n",
    "    print(f\"Resampled dataset shape: {df.lab_flag.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create a results folder\n",
    "if not os.path.exists(os.path.join(repo_location, \"Notebooks/\", panel, \"results\")):\n",
    "    os.makedirs(os.path.join(repo_location, \"Notebooks/\", panel, \"results\")) \n",
    "#Create a plots folder\n",
    "if not os.path.exists(os.path.join(repo_location, \"Notebooks/\", panel, \"plots\")):\n",
    "    os.makedirs(os.path.join(repo_location, \"Notebooks/\", panel, \"plots\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.resnet = resnet50(weights=None)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = nn.Linear(2048, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.2, inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.resnet.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "class ResNet50_age_gender(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNet50_age_gender, self).__init__()\n",
    "        self.resnet = resnet50(weights=None)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = nn.Identity()  # Remove the original fully connected layer\n",
    "        self.dropout = nn.Dropout(p=0.2, inplace=False)\n",
    "        self.fc = nn.Linear(2048 + 2, num_classes)  # 2048 for ResNet50 features + 2 for age and gender\n",
    "\n",
    "    def forward(self, x_img, age, gender):\n",
    "        # Process image data through ResNet50\n",
    "        x = self.resnet.conv1(x_img)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Combine image features with age and gender\n",
    "        age_gender = torch.cat((age.unsqueeze(1), gender.unsqueeze(1)), dim=1)  # Shape: (batch_size, 2)\n",
    "        combined = torch.cat((x, age_gender), dim=1)  # Shape: (batch_size, 2048 + 2)\n",
    "\n",
    "        # Pass combined features through the final classification layer\n",
    "        output = self.fc(combined)\n",
    "        output = F.softmax(output, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df.lab_flag.value_counts().to_numpy()\n",
    "total_samples = class_counts.sum()\n",
    "class_weights = total_samples / (class_counts.shape[0] * class_counts)\n",
    "if class_weights.max()/class_weights.min() <= 2:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "    if df.lab_flag.value_counts().index[0] == 1:\n",
    "        class_weights_tensor = class_weights_tensor.flip(0)\n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "    print(df.lab_flag.value_counts())\n",
    "    print(class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `dataset` is your PyTorch dataset\n",
    "# dataset = YourDatasetClass()\n",
    "dataset = MyDataset(df)\n",
    "\n",
    "# Step 1: Split the dataset indices\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "# First split: train and temporary (which will be further split into validation and test)\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.4, random_state=42)\n",
    "\n",
    "# Second split: validation and test (split the temporary set into validation and test)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 2: Create subsets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Step 3: Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gender_age_used == \"No_GA\":\n",
    "    model = ResNet50(num_classes = 2)\n",
    "else:\n",
    "    model = ResNet50_age_gender(num_classes = 2)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "best_val_acc = 0\n",
    "train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "best_val_acc = 0\n",
    "with tqdm(total=num_epochs) as pbar:    \n",
    "    for epoch in range(1, int(num_epochs + 1)):\n",
    "        \n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion,\n",
    "        epoch, device, gender_age_used, scheduler=scheduler)\n",
    "        \n",
    "        val_loss, val_acc, best_val_acc = validate(model, val_loader,\n",
    "        criterion, best_val_acc, device, test, repo_location, gender_age_used)\n",
    "\n",
    "        results_dict = {\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc\n",
    "        }\n",
    "\n",
    "        pbar.set_description(f\"{test} Epoch {epoch}/{num_epochs} - Train Loss: {train_loss:.2f} - Train Acc: {train_acc*100:.2f} - Val Loss: {val_loss:.2f} - Val Acc: {val_acc*100:.2f}\")\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([results_dict])], ignore_index=True)\n",
    "        pbar.update(1)\n",
    "\n",
    "plot_loss_accuracy(results_df.train_loss, results_df.train_acc, results_df.val_loss, results_df.val_acc, test, gender_age_used)\n",
    "results_df.to_csv(os.path.join(repo_location, f\"results/{test}_{gender_age_used}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryAUROC, BinaryAveragePrecision\n",
    "#if csv results file does not exist, create one\n",
    "if not os.path.exists(os.path.join(repo_location, \"Notebooks\", panel, f\"results/{panel}_test_results.csv\")):\n",
    "    test_results = pd.DataFrame()\n",
    "else:\n",
    "    test_results = pd.read_csv(os.path.join(repo_location, \"Notebooks\", panel, f\"results/{panel}_test_results.csv\"))\n",
    "\n",
    "#Load the best model\n",
    "if gender_age_used == \"No_GA\":\n",
    "    model = ResNet50(num_classes = 2)\n",
    "else:\n",
    "    model = ResNet50_age_gender(num_classes = 2)\n",
    "model.load_state_dict(torch.load(os.path.join(repo_location, f\"models/bestmodel_{test}_{gender_age_used}.pth\")))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "#Create a confusion matrix\n",
    "confusion_matrix = np.zeros((2, 2))\n",
    "outputs = torch.tensor([]).to(device)\n",
    "targets = torch.tensor([]).to(device)\n",
    "\n",
    "#Iterate over the test data\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        if gender_age_used == \"GA_used\":\n",
    "            inputs, age, gender, labels = data\n",
    "            inputs, age, gender, labels = inputs.to(device), age.to(device), gender.to(device), labels.to(device)\n",
    "            labels = labels.long()  # Convert labels to Long type\n",
    "            output = model(inputs, age, gender)\n",
    "        else:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "            output = model(inputs.unsqueeze(1))\n",
    "        \n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        outputs = torch.cat((outputs, predicted), 0)\n",
    "        targets = torch.cat((targets, labels), 0)\n",
    "\n",
    "        for j in range(len(predicted)):\n",
    "            confusion_matrix[labels[j], predicted[j]] += 1\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "\n",
    "# Calculate precision and recall for class 1\n",
    "if np.sum(confusion_matrix[:, 1]) == 0:\n",
    "    precision = 0\n",
    "else:\n",
    "    precision = confusion_matrix[1, 1] / np.sum(confusion_matrix[:, 1])\n",
    "\n",
    "if np.sum(confusion_matrix[1, :]) == 0:\n",
    "    recall = 0\n",
    "else:\n",
    "    recall = confusion_matrix[1, 1] / np.sum(confusion_matrix[1, :])\n",
    "\n",
    "# Calculate F1 score for class 1\n",
    "if precision + recall == 0:\n",
    "    f1 = 0\n",
    "else:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate specificity and NPV for class 0\n",
    "if np.sum(confusion_matrix[0, :]) == 0:\n",
    "    specificity = 0\n",
    "else:\n",
    "    specificity = confusion_matrix[0, 0] / np.sum(confusion_matrix[0, :])\n",
    "if np.sum(confusion_matrix[:, 0]) == 0:\n",
    "    npv = 0\n",
    "else:     \n",
    "    npv = confusion_matrix[0, 0] / np.sum(confusion_matrix[:, 0])\n",
    "\n",
    "#Calculate auroc and auprc\n",
    "auroc = BinaryAUROC()\n",
    "auprc = BinaryAveragePrecision()\n",
    "\n",
    "\n",
    "#Create a dictionary of the results\n",
    "results_dict = {\n",
    "    'test': test,\n",
    "    'class_0_sample':df[df.lab_flag == 0].shape[0],\n",
    "    'class_1_sample':df[df.lab_flag == 1].shape[0], \n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'specificity': specificity,\n",
    "    'npv': npv,\n",
    "    'auroc': auroc(outputs, targets.type(torch.int64)).item(),\n",
    "    'auprc': auprc(outputs, targets.type(torch.int64)).item(),\n",
    "    'interval': f\"{int(time.split(' ')[0]) * 2} min\",\n",
    "    'Gender_age_used': gender_age_used,\n",
    "    'notes': f'''''' \n",
    "}\n",
    "\n",
    "#Append the results to the test_results dataframe\n",
    "test_results = pd.concat([test_results, pd.DataFrame([results_dict])], ignore_index=True)\n",
    "\n",
    "#Save the results to a csv file\n",
    "test_results.to_csv(os.path.join(repo_location, \"Notebooks\", panel, f\"results/{panel}_test_results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'RDW',\n",
       " 'class_0_sample': 83821,\n",
       " 'class_1_sample': 64077,\n",
       " 'accuracy': 0.784448951994591,\n",
       " 'precision': 0.7699137072685032,\n",
       " 'recall': 0.7203074056823474,\n",
       " 'f1': 0.7442849121681239,\n",
       " 'specificity': 0.833932207449994,\n",
       " 'npv': 0.7944431766316751,\n",
       " 'auroc': 0.7771198153495789,\n",
       " 'auprc': 0.6763797998428345,\n",
       " 'interval': '30 min',\n",
       " 'Gender_age_used': 'No_GA',\n",
       " 'notes': ''}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_age_used = \"GA_used\"\n",
    "df = pd.read_csv(file_path, dtype=dtypes)\n",
    "if gender_age_used == \"No_GA\":\n",
    "    df = df.drop(columns=['Gender', 'Age'])\n",
    "if 'SubjectID' in df.columns:\n",
    "    df = df.drop(columns=['SubjectID'])\n",
    "df.lab_flag.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: lab_flag\n",
      "1    83305\n",
      "0    16661\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Downsample the class with the majority of data\n",
    "df_majority = df[df.lab_flag == df.lab_flag.value_counts().index[0]]  \n",
    "df_minority = df[df.lab_flag == df.lab_flag.value_counts().index[1]]\n",
    "\n",
    "# If the majority class is at least 5 times the size of the minority class\n",
    "if len(df_majority) / len(df_minority) >= 5:\n",
    "    # Downsample majority class\n",
    "    df_majority_downsampled = df_majority.sample(n=int(len(df_minority)*5), random_state=42)\n",
    "\n",
    "    # Combine minority class with downsampled majority class\n",
    "    df = pd.concat([df_majority_downsampled, df_minority])\n",
    "    print(f\"Resampled dataset shape: {df.lab_flag.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df.lab_flag.value_counts().to_numpy()\n",
    "total_samples = class_counts.sum()\n",
    "class_weights = total_samples / (class_counts.shape[0] * class_counts)\n",
    "if class_weights.max()/class_weights.min() <= 2:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "    if df.lab_flag.value_counts().index[0] == 1:\n",
    "        class_weights_tensor = class_weights_tensor.flip(0)\n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "    print(df.lab_flag.value_counts())\n",
    "    print(class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `dataset` is your PyTorch dataset\n",
    "# dataset = YourDatasetClass()\n",
    "dataset = MyDataset(df)\n",
    "\n",
    "# Step 1: Split the dataset indices\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "# First split: train and temporary (which will be further split into validation and test)\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.4, random_state=42)\n",
    "\n",
    "# Second split: validation and test (split the temporary set into validation and test)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 2: Create subsets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Step 3: Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gender_age_used == \"No_GA\":\n",
    "    model = ResNet50(num_classes = 2)\n",
    "else:\n",
    "    model = ResNet50_age_gender(num_classes = 2)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "best_val_acc = 0\n",
    "train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "best_val_acc = 0\n",
    "with tqdm(total=num_epochs) as pbar:    \n",
    "    for epoch in range(1, int(num_epochs + 1)):\n",
    "        \n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion,\n",
    "        epoch, device, gender_age_used, scheduler=scheduler)\n",
    "        \n",
    "        val_loss, val_acc, best_val_acc = validate(model, val_loader,\n",
    "        criterion, best_val_acc, device, test, repo_location, gender_age_used)\n",
    "\n",
    "        results_dict = {\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc\n",
    "        }\n",
    "\n",
    "        pbar.set_description(f\"{test} Epoch {epoch}/{num_epochs} - Train Loss: {train_loss:.2f} - Train Acc: {train_acc*100:.2f} - Val Loss: {val_loss:.2f} - Val Acc: {val_acc*100:.2f}\")\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([results_dict])], ignore_index=True)\n",
    "        pbar.update(1)\n",
    "\n",
    "plot_loss_accuracy(results_df.train_loss, results_df.train_acc, results_df.val_loss, results_df.val_acc, test, gender_age_used)\n",
    "results_df.to_csv(os.path.join(repo_location, f\"results/{test}_{gender_age_used}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryAUROC, BinaryAveragePrecision\n",
    "#if csv results file does not exist, create one\n",
    "if not os.path.exists(os.path.join(repo_location, \"Notebooks\", panel, f\"results/{panel}_test_results.csv\")):\n",
    "    test_results = pd.DataFrame()\n",
    "else:\n",
    "    test_results = pd.read_csv(os.path.join(repo_location, \"Notebooks\", panel, f\"results/{panel}_test_results.csv\"))\n",
    "\n",
    "#Load the best model\n",
    "if gender_age_used == \"No_GA\":\n",
    "    model = ResNet50(num_classes = 2)\n",
    "else:\n",
    "    model = ResNet50_age_gender(num_classes = 2)\n",
    "model.load_state_dict(torch.load(os.path.join(repo_location, f\"models/bestmodel_{test}_{gender_age_used}.pth\")))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "#Create a confusion matrix\n",
    "confusion_matrix = np.zeros((2, 2))\n",
    "outputs = torch.tensor([]).to(device)\n",
    "targets = torch.tensor([]).to(device)\n",
    "\n",
    "#Iterate over the test data\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        if gender_age_used == \"GA_used\":\n",
    "            inputs, age, gender, labels = data\n",
    "            inputs, age, gender, labels = inputs.to(device), age.to(device), gender.to(device), labels.to(device)\n",
    "            labels = labels.long()  # Convert labels to Long type\n",
    "            output = model(inputs, age, gender)\n",
    "        else:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "            output = model(inputs.unsqueeze(1))\n",
    "        \n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        outputs = torch.cat((outputs, predicted), 0)\n",
    "        targets = torch.cat((targets, labels), 0)\n",
    "\n",
    "        for j in range(len(predicted)):\n",
    "            confusion_matrix[labels[j], predicted[j]] += 1\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "\n",
    "# Calculate precision and recall for class 1\n",
    "if np.sum(confusion_matrix[:, 1]) == 0:\n",
    "    precision = 0\n",
    "else:\n",
    "    precision = confusion_matrix[1, 1] / np.sum(confusion_matrix[:, 1])\n",
    "\n",
    "if np.sum(confusion_matrix[1, :]) == 0:\n",
    "    recall = 0\n",
    "else:\n",
    "    recall = confusion_matrix[1, 1] / np.sum(confusion_matrix[1, :])\n",
    "\n",
    "# Calculate F1 score for class 1\n",
    "if precision + recall == 0:\n",
    "    f1 = 0\n",
    "else:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate specificity and NPV for class 0\n",
    "if np.sum(confusion_matrix[0, :]) == 0:\n",
    "    specificity = 0\n",
    "else:\n",
    "    specificity = confusion_matrix[0, 0] / np.sum(confusion_matrix[0, :])\n",
    "if np.sum(confusion_matrix[:, 0]) == 0:\n",
    "    npv = 0\n",
    "else:     \n",
    "    npv = confusion_matrix[0, 0] / np.sum(confusion_matrix[:, 0])\n",
    "\n",
    "#Calculate auroc and auprc\n",
    "auroc = BinaryAUROC()\n",
    "auprc = BinaryAveragePrecision()\n",
    "\n",
    "\n",
    "#Create a dictionary of the results\n",
    "results_dict = {\n",
    "    'test': test,\n",
    "    'class_0_sample':df[df.lab_flag == 0].shape[0],\n",
    "    'class_1_sample':df[df.lab_flag == 1].shape[0], \n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'specificity': specificity,\n",
    "    'npv': npv,\n",
    "    'auroc': auroc(outputs, targets.type(torch.int64)).item(),\n",
    "    'auprc': auprc(outputs, targets.type(torch.int64)).item(),\n",
    "    'interval': f\"{int(time.split(' ')[0]) * 2} min\",\n",
    "    'Gender_age_used': gender_age_used,\n",
    "    'notes': f'''''' \n",
    "}\n",
    "\n",
    "#Append the results to the test_results dataframe\n",
    "test_results = pd.concat([test_results, pd.DataFrame([results_dict])], ignore_index=True)\n",
    "\n",
    "#Save the results to a csv file\n",
    "test_results.to_csv(os.path.join(repo_location, \"Notebooks\", panel, f\"results/{panel}_test_results.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# def duplicate_file_to_targets(source_file, target_files):\n",
    "#     \"\"\"\n",
    "#     Replaces each target file with the contents of the source file while retaining the target file's name.\n",
    "\n",
    "#     Args:\n",
    "#         source_file (str): Path to the source file to duplicate.\n",
    "#         target_files (list): List of paths to the target files to be replaced.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(source_file):\n",
    "#         print(f\"Source file '{source_file}' does not exist.\")\n",
    "#         return\n",
    "\n",
    "#     for target_file in target_files:\n",
    "#         try:\n",
    "#             if os.path.exists(target_file):\n",
    "#                 os.remove(target_file)  # Remove the existing target file\n",
    "#             shutil.copy(source_file, target_file)  # Copy the source file to the target location\n",
    "#             print(f\"Copied '{source_file}' to '{target_file}'\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to copy '{source_file}' to '{target_file}': {e}\")\n",
    "\n",
    "# # Example usage\n",
    "# source_file = 'Basophils_resnet50.ipynb'  # Path to the source file\n",
    "# target_files = [\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\Hematocrit_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\Eosinophils_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\RDW_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\MCHC_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\MCH_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\MCV_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\Monocytes_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\Neutrophils_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\NRBCs_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\Platelets_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\RBCs_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\Lymphocytes_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\WBC_resnet50.ipynb',\n",
    "#     r'D:\\simedy\\Notebooks\\CBC\\Hemoglobin_resnet50.ipynb'\n",
    "#     # Add more target file paths as needed\n",
    "# ]\n",
    "\n",
    "# duplicate_file_to_targets(source_file, target_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
