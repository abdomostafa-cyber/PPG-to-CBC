{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mat73 import loadmat\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'D:\\PulseDB_Vital'\n",
    "file = 'p000001.mat'\n",
    "\n",
    "mat_data = loadmat(os.path.join(Path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ABP_F', 'ABP_Lag', 'ABP_Raw', 'ABP_SPeaks', 'ABP_Turns', 'Age', 'BMI', 'CaseID', 'ECG_F', 'ECG_RPeaks', 'ECG_Raw', 'ECG_Record', 'ECG_Record_F', 'Gender', 'Height', 'IncludeFlag', 'PPG_ABP_Corr', 'PPG_F', 'PPG_Raw', 'PPG_Record', 'PPG_Record_F', 'PPG_SPeaks', 'PPG_Turns', 'SegDBP', 'SegSBP', 'SegmentID', 'SubjectID', 'T', 'Weight', 'WinID', 'WinSeqID'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_data['Subj_Wins'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.09463953, 0.10125966, 0.10965594, ..., 0.14367954, 0.11535997,\n",
       "       0.09382765])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mat_data['Subj_Wins']['PPG_Raw'][0][0].shape)\n",
    "mat_data['Subj_Wins']['PPG_Raw'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(55.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_data['Subj_Wins']['SegmentID'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a new folder to house the modified mat files\n",
    "os.mkdir('D:\\PulseDB_Vital_modified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = os.path.join(Path, file)\n",
    "\n",
    "# Load the .mat file\n",
    "mat_data = loadmat(input_file)\n",
    "\n",
    "# Extract CaseID and SegmentID from the .mat file\n",
    "case_ids_list = mat_data['Subj_Wins']['CaseID']\n",
    "segment_ids_list = mat_data['Subj_Wins']['SegmentID']\n",
    "\n",
    "# Convert case_ids_list and segment_ids_list from lists of arrays to flat lists\n",
    "case_ids = [case_id[0] for case_id in case_ids_list]\n",
    "segment_ids = [segment_id[0] for segment_id in segment_ids_list]\n",
    "\n",
    "# Convert to a DataFrame\n",
    "data = {\n",
    "    'CaseID': case_ids,\n",
    "    'SegmentID': segment_ids\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d4814751d44e02a202224f327017a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking if any of the files has more than 1 CaseID\n",
    "for file in tqdm(os.listdir(Path)):\n",
    "    input_file = os.path.join(Path, file)\n",
    "    # Extract CaseID and SegmentID from the .mat file\n",
    "    case_ids_list = mat_data['Subj_Wins']['CaseID']\n",
    "    segment_ids_list = mat_data['Subj_Wins']['SegmentID']\n",
    "\n",
    "    # Convert case_ids_list and segment_ids_list from lists of arrays to flat lists\n",
    "    case_ids = [case_id[0] for case_id in case_ids_list]\n",
    "    segment_ids = [segment_id[0] for segment_id in segment_ids_list]\n",
    "\n",
    "    # Convert to a DataFrame\n",
    "    data = {\n",
    "        'CaseID': case_ids,\n",
    "        'SegmentID': segment_ids\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if df.CaseID.value_counts().index.size > 1:\n",
    "        print(f'File {file} has more than 1 CaseID')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseID\n",
       "c0822    1353\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.CaseID.value_counts().index.size)\n",
    "df.CaseID.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlike MIMIC_DB, Vital_DB does not contain multiple caseIDs per patient, and the caseID does not encode the time of admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16191909089b497bb5854d3c08d4f000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing .mat files:   0%|          | 0/2938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of keys to include within the 'Subj_Wins' group\n",
    "keys_to_include = [\n",
    "    'ABP_Raw', 'Age', 'ECG_Raw', 'Gender',\n",
    "    'PPG_Raw', 'SegmentID', 'SubjectID', 'T'\n",
    "]\n",
    "\n",
    "def process_data(data, output_group):\n",
    "    for key, value in data.items():\n",
    "        if key not in keys_to_include:\n",
    "            continue\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            sub_group = output_group.create_group(key)\n",
    "            process_data(value, sub_group)\n",
    "        else:\n",
    "            try:\n",
    "                if isinstance(value, list):\n",
    "                    value = np.array(value)\n",
    "                if isinstance(value, np.ndarray) and value.dtype == 'object':\n",
    "                    uniform_array = np.array([np.asarray(x) for x in value])\n",
    "                    output_group.create_dataset(key, data=uniform_array)\n",
    "                elif isinstance(value, np.ndarray) and value.size == 1:\n",
    "                    scalar_value = value.item()\n",
    "                    output_group.create_dataset(key, data=scalar_value)\n",
    "                elif isinstance(value, np.ndarray) and np.issubdtype(value.dtype, np.str_):\n",
    "                    output_group.create_dataset(key, data=value.astype('S'))\n",
    "                else:\n",
    "                    output_group.create_dataset(key, data=value)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing key {key}: {e}\")\n",
    "\n",
    "def process_mat_file(input_file, output_file):\n",
    "    # Load the .mat file\n",
    "    mat_data = loadmat(input_file)\n",
    "\n",
    "    # Extract SegmentID from the .mat file\n",
    "    # case_ids_list = mat_data['Subj_Wins']['CaseID']\n",
    "    segment_ids_list = mat_data['Subj_Wins']['SegmentID']\n",
    "\n",
    "    if type(segment_ids_list) == list:\n",
    "        # Convert segment_ids_list from lists of arrays to flat lists\n",
    "        # case_ids = [case_id[0] for case_id in case_ids_list]\n",
    "        segment_ids = [segment_id[0] for segment_id in segment_ids_list]\n",
    "\n",
    "        # Convert to a DataFrame\n",
    "        data = {\n",
    "            # 'CaseID': case_ids,\n",
    "            'SegmentID': segment_ids\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Convert CaseID to datetime\n",
    "        # df['CaseID_datetime'] = pd.to_datetime(df['CaseID'], format='%Y-%m-%d-%H-%M')\n",
    "\n",
    "        # Calculate the time of the segment (in seconds)\n",
    "        df['SegmentTime'] = df['SegmentID'] * 10\n",
    "\n",
    "        # Add the segment time to CaseID_datetime\n",
    "        # df['FinalTime'] = df['CaseID_datetime'] + pd.to_timedelta(df['SegmentTime'], unit='s')\n",
    "\n",
    "        # Convert FinalTime to string format to store back in .mat file\n",
    "        df['FinalTime_str'] = pd.to_datetime(df['SegmentTime'], unit='s').dt.strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "        Segment_Time = df['FinalTime_str'].values.reshape(-1, 1)\n",
    "\n",
    "        # Add Segment_Time to the original data\n",
    "        mat_data['Subj_Wins']['Segment_Time'] = Segment_Time\n",
    "\n",
    "        # Save the data back into a .h5py file with only the necessary variables\n",
    "        with h5py.File(output_file, 'w') as out_f:\n",
    "            subj_wins_group = out_f.create_group('Subj_Wins')\n",
    "            process_data(mat_data['Subj_Wins'], subj_wins_group)\n",
    "            subj_wins_group.create_dataset('Segment_Time', data=Segment_Time.astype('S'))\n",
    "\n",
    "def process_multiple_mat_files(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    mat_files = [file_name for file_name in os.listdir(input_dir) if file_name.endswith('.mat')]\n",
    "    for file_name in tqdm(mat_files, desc=\"Processing .mat files\"):\n",
    "        input_file = os.path.join(input_dir, file_name)\n",
    "        output_file = os.path.join(output_dir, file_name)\n",
    "        process_mat_file(input_file, output_file)\n",
    "\n",
    "# Example usage\n",
    "input_directory = 'D:/PulseDB_Vital'\n",
    "output_directory = 'D:/PulseDB_Vital_modified'\n",
    "process_multiple_mat_files(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5_file(file_path):\n",
    "    def recursively_load_data(h5_obj):\n",
    "        if isinstance(h5_obj, h5py.Dataset):\n",
    "            data = h5_obj[()]\n",
    "            if isinstance(data, bytes):  # Decode byte strings\n",
    "                return data.decode()\n",
    "            elif isinstance(data, np.ndarray) and data.dtype.type is np.bytes_:\n",
    "                return data.astype(str)  # Decode byte strings in numpy arrays\n",
    "            return data\n",
    "        elif isinstance(h5_obj, h5py.Group):\n",
    "            data = {}\n",
    "            for key, item in h5_obj.items():\n",
    "                data[key] = recursively_load_data(item)\n",
    "            return data\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type: {type(h5_obj)}\")\n",
    "    \n",
    "    # Open the HDF5 file and load data\n",
    "    with h5py.File(file_path, 'r') as h5_file:\n",
    "        data = recursively_load_data(h5_file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ABP_F', 'ABP_Lag', 'ABP_Raw', 'ABP_SPeaks', 'ABP_Turns', 'Age', 'BMI', 'CaseID', 'ECG_F', 'ECG_RPeaks', 'ECG_Raw', 'ECG_Record', 'ECG_Record_F', 'Gender', 'Height', 'IncludeFlag', 'PPG_ABP_Corr', 'PPG_F', 'PPG_Raw', 'PPG_Record', 'PPG_Record_F', 'PPG_SPeaks', 'PPG_Turns', 'SegDBP', 'SegSBP', 'SegmentID', 'SubjectID', 'T', 'Weight', 'WinID', 'WinSeqID'])\n",
      "dict_keys(['ABP_Raw', 'Age', 'ECG_Raw', 'Gender', 'PPG_Raw', 'SegmentID', 'Segment_Time', 'SubjectID', 'T'])\n"
     ]
    }
   ],
   "source": [
    "input_file = 'D:/PulseDB_Vital/p000003.mat'\n",
    "input_file_modified = 'D:/PulseDB_Vital_modified/p000003.mat'\n",
    "\n",
    "unmodified_data = loadmat(input_file)\n",
    "modified_data = load_h5_file(input_file_modified)\n",
    "\n",
    "#Compare the keys available in the unmodified and modified data\n",
    "print(unmodified_data['Subj_Wins'].keys())\n",
    "print(modified_data['Subj_Wins'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1970-01-01-00-03-30'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the segmentID and Segment_Time correspond to the same time\n",
    "'''\n",
    "Remember that segmentID represents a time stamp in seconds divided by 10 \n",
    "so to change from the time displayed in segmentID to the one in Segment_Time:\n",
    "    1. Multiply the number in segmentID by 10\n",
    "    2. Divide by 60 to get the minutes\n",
    "    3. Multiply the remainder by 60 to get the seconds\n",
    "'''\n",
    "print(unmodified_data['Subj_Wins']['SegmentID'][15][0] * 10)\n",
    "modified_data['Subj_Wins']['Segment_Time'][15][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
