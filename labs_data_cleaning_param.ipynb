{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d971c3",
   "metadata": {},
   "source": [
    "# ðŸ§ª labs_data_cleaning_param.ipynb\n",
    "\n",
    "Streaming-friendly lab data cleaner for large MIMIC-III LABEVENTS files.\n",
    "\n",
    "This notebook:\n",
    "- Reads LABEVENTS.csv in chunks (memory-safe)\n",
    "- Filters for CBC tests\n",
    "- Keeps only rows where FLAG == 'abnormal' or NaN (normal)\n",
    "- Encodes FLAG as 1 (abnormal) or 0 (normal)\n",
    "- Formats SUBJECT_ID as 'pXXXXXX'\n",
    "- Uses configs/labs_cleaning.yaml for settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fac04ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.9\n",
      "pandas 2.2.2\n",
      "numpy 2.0.2\n",
      "yaml 6.0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, importlib\n",
    "print('Python:', sys.version.split()[0])\n",
    "for pkg in ['pandas','numpy','yaml']:\n",
    "    try:\n",
    "        m = importlib.import_module(pkg)\n",
    "        print(pkg, getattr(m, '__version__', 'n/a'))\n",
    "    except Exception as e:\n",
    "        print(pkg, 'not installed:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a7fc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration from: configs/labs_cleaning.yaml\n",
      "{'labs_csv': 'data/raw/LABEVENTS.csv', 'd_labitems_csv': 'data/raw/D_LABITEMS.csv', 'output_clean_csv': 'data/clean/labs_cbc_clean.csv', 'subject_filter_csv': None, 'columns': {'subject_id': ['SUBJECT_ID', 'subject_id'], 'hadm_id': ['HADM_ID', 'hadm_id'], 'charttime': ['CHARTTIME', 'charttime'], 'itemid': ['ITEMID', 'itemid'], 'label': ['LABEL', 'label', 'TESTNAME', 'test_name'], 'value': ['VALUENUM', 'value', 'VALUE'], 'valueuom': ['VALUEUOM', 'valueuom'], 'flag': ['FLAG', 'flag', 'ABNORMAL', 'abnormal', 'RESULTS', 'results']}, 'cbc_labels': ['Hemoglobin', 'Hematocrit', 'WBC', 'Platelet Count', 'RBC', 'MCV', 'MCH', 'MCHC', 'RDW', 'Neutrophils', 'Lymphocytes', 'Monocytes', 'Eosinophils', 'Basophils'], 'cbc_itemids': [], 'flag_keep': ['positive', 'negative', 'abnormal', 'high', 'low'], 'drop_na_value': True, 'dedupe_keys': ['subject_id', 'charttime', 'label'], 'time_format_out': '%Y-%m-%d %H:%M:%S', 'chunksize': 300000, 'streaming': True, 'memory_safe': True, 'notes': ['Streaming mode enabled to handle 18GB+ LABEVENTS.csv.', \"Adjust 'chunksize' based on available RAM.\", 'Provide D_LABITEMS.csv for ITEMID mapping and faster CBC filtering.']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load configuration\n",
    "from pathlib import Path\n",
    "import yaml, os\n",
    "\n",
    "CFG_PATH = os.environ.get(\"CFG\", \"configs/labs_cleaning.yaml\")\n",
    "with open(CFG_PATH, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "L = cfg[\"labs_cleaning\"]\n",
    "print(\"Loaded configuration from:\", CFG_PATH)\n",
    "print(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b856b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Streaming complete. Scanned ~27,854,055 rows; kept ~2,991,947.\n",
      "Output saved to: data/clean/labs_cbc_clean.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Streaming cleaner (avoids OOM, processes 18GB+ files safely)\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from csv import QUOTE_MINIMAL\n",
    "\n",
    "def choose_col(df, candidates, required=False, name=\"\"):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Required column not found for {name}: candidates={candidates}\")\n",
    "    return None\n",
    "\n",
    "def load_d_labitems(path):\n",
    "    if path and Path(path).exists():\n",
    "        d = pd.read_csv(path, low_memory=False)\n",
    "        label_col = next((c for c in [\"LABEL\",\"label\",\"TESTNAME\",\"test_name\"] if c in d.columns), None)\n",
    "        itemid_col = next((c for c in [\"ITEMID\",\"itemid\"] if c in d.columns), None)\n",
    "        if label_col and itemid_col:\n",
    "            return d[[itemid_col,label_col]].rename(columns={itemid_col:\"ITEMID\", label_col:\"LABEL\"})\n",
    "    return None\n",
    "\n",
    "def normalize_flags(s):\n",
    "    if s is None: return None\n",
    "    s2 = s.astype(str).str.lower().str.strip()\n",
    "    return s2.replace({\n",
    "        \"abnormal\": \"abnormal\",\n",
    "        \"high\": \"high\",\n",
    "        \"low\": \"low\",\n",
    "        \"pos\": \"positive\",\n",
    "        \"neg\": \"negative\",\n",
    "        \"positive\": \"positive\",\n",
    "        \"negative\": \"negative\"\n",
    "    })\n",
    "\n",
    "Path(Path(L[\"output_clean_csv\"]).parent).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dli = load_d_labitems(L.get(\"d_labitems_csv\"))\n",
    "cbc_labels = set(L.get(\"cbc_labels\", []))\n",
    "cbc_itemids = set(L.get(\"cbc_itemids\", []))\n",
    "if not cbc_itemids and dli is not None and cbc_labels:\n",
    "    cbc_itemids = set(dli.loc[dli[\"LABEL\"].isin(cbc_labels), \"ITEMID\"].astype(\"Int64\").dropna().astype(int).tolist())\n",
    "\n",
    "sample = pd.read_csv(L[\"labs_csv\"], nrows=1000, low_memory=False)\n",
    "col_subject = choose_col(sample, L[\"columns\"][\"subject_id\"]) or \"SUBJECT_ID\"\n",
    "col_time    = choose_col(sample, L[\"columns\"][\"charttime\"]) or \"CHARTTIME\"\n",
    "col_itemid  = choose_col(sample, L[\"columns\"][\"itemid\"]) or \"ITEMID\"\n",
    "col_label   = choose_col(sample, L[\"columns\"][\"label\"])\n",
    "col_value   = choose_col(sample, L[\"columns\"][\"value\"]) or \"VALUENUM\"\n",
    "col_uom     = choose_col(sample, L[\"columns\"][\"valueuom\"]) or \"VALUEUOM\"\n",
    "col_flag    = choose_col(sample, L[\"columns\"][\"flag\"])\n",
    "\n",
    "usecols = sorted(set(filter(None, [col_subject, col_time, col_itemid, col_label, col_value, col_uom, col_flag])))\n",
    "dtype_map = {}\n",
    "if col_itemid: dtype_map[col_itemid] = \"Int64\"\n",
    "if col_value: dtype_map[col_value] = \"float32\"\n",
    "if col_subject: dtype_map[col_subject] = \"Int64\"\n",
    "\n",
    "wrote_header = False\n",
    "kept = 0\n",
    "total = 0\n",
    "chunksize = int(L.get(\"chunksize\", 300_000))\n",
    "\n",
    "for chunk in pd.read_csv(L[\"labs_csv\"], usecols=usecols, dtype=dtype_map, chunksize=chunksize, low_memory=True):\n",
    "    total += len(chunk)\n",
    "    mask = pd.Series(False, index=chunk.index)\n",
    "    if cbc_itemids:\n",
    "        mask = mask | chunk[col_itemid].isin(list(cbc_itemids))\n",
    "    if col_label and cbc_labels:\n",
    "        mask = mask | chunk[col_label].astype(str).isin(cbc_labels)\n",
    "    chunk = chunk[mask]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"subject_id\": chunk[col_subject].astype(\"Int64\"),\n",
    "        \"charttime\": pd.to_datetime(chunk[col_time], errors=\"coerce\"),\n",
    "        \"label\": chunk[col_label].astype(str) if col_label else None,\n",
    "        \"itemid\": chunk[col_itemid].astype(\"Int64\") if col_itemid else None,\n",
    "        \"value\": pd.to_numeric(chunk[col_value], errors=\"coerce\") if col_value else None,\n",
    "        \"valueuom\": chunk[col_uom].astype(str) if col_uom else None,\n",
    "        \"flag\": normalize_flags(chunk[col_flag]) if col_flag else None,\n",
    "    })\n",
    "\n",
    "    # Keep only abnormal or NaN flags, encode abnormal->1, NaN->0\n",
    "    if \"flag\" in out.columns:\n",
    "        out[\"flag\"] = out[\"flag\"].astype(\"string\").str.lower().str.strip()\n",
    "        out = out[(out[\"flag\"] == \"abnormal\") | (out[\"flag\"].isna())]\n",
    "        out[\"flag\"] = out[\"flag\"].map({\"abnormal\": 1}).fillna(0).astype(\"Int8\")\n",
    "\n",
    "    # Format subject_id as pXXXXXX\n",
    "    out[\"subject_id\"] = out[\"subject_id\"].apply(lambda x: f\"p{int(x):06d}\" if pd.notna(x) else x)\n",
    "\n",
    "    # Drop missing value rows if configured\n",
    "    if L.get(\"drop_na_value\", True):\n",
    "        out = out[out[\"value\"].notna()]\n",
    "\n",
    "    out[\"charttime\"] = out[\"charttime\"].dt.strftime(L.get(\"time_format_out\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "    kept += len(out)\n",
    "    out.to_csv(L[\"output_clean_csv\"], mode=\"a\", index=False, header=(not wrote_header), quoting=QUOTE_MINIMAL)\n",
    "    wrote_header = True\n",
    "\n",
    "print(f\"âœ… Streaming complete. Scanned ~{total:,} rows; kept ~{kept:,}.\")\n",
    "print(f\"Output saved to: {L['output_clean_csv']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
